<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[STL——迭代器]]></title>
    <url>%2F2018%2F05%2F21%2F2018-5-21STL_Iterator%2F</url>
    <content type="text"><![CDATA[本文主要关注STL的迭代器，浅谈迭代器在STL中扮演什么样的角色，以及它是怎么起作用的。 1 没有迭代器的日子刚学数据结构与算法的时候，我们写一个数组容器array，写一个链表容器list，如果要写一个查找算法find，我们的做法是： 为array写一个array_find，为list写一个list_find。当有更多不同的数据结构，我们就要为不同的数据结构都分别写一个 find算法。无比繁琐。 反观find算法，它无非是从容器的第一个节点开始，每次往前走一个节点，然后进行比对。关键的不同在于不同的容器每向前走 一步的行为方式是不同的，对数组是直接往前走一个元素的尺寸；对于链表，需要找到下一个节点的地址，然后跳转到那个地址。 怎么样才能让一个find，可以操作各种不同的容器呢？让算法只关心它自己的核心行为，也就是算法行为本身（find: 从第一个元素，比对一次，找下一个元素，再比对，再找下一个，直到找到或到达容器尾部）。而具体在容器上的行为，算法不关心。 2 引入迭代器为了让算法和容器之间解耦，我们引入一个“中间人”角色。我们为每个容器设计一个中间人，这个中间人代表着容器，对外它们有着一样的接口，对内，不同容器的中间人是不一样的。承接上文，这个“中间人”就是让算法“驱使”的。算法让“中间人”往前走一步，它就走一步。但是具体是怎么前进的，中间人知道就可以了，算法不理会。而这个中间人，就是所谓的迭代器。 迭代器其实是23种设计模式中的一种，模式定义如下： 提供一种方法，使之能够依序巡访某个聚合物（容器）所含的各个元素，而又无需暴露该聚合物的内部表述方式。 另一方面，STL的中心思想在于：将数据容器和算法分开、彼此独立设计，最后再用迭代器联系在一起，完美！ 3 作为一个代表，迭代器需要知道容器哪些属性迭代器最终是被算法所使用的。因此，迭代器需要知道容器的哪些信息，完全是由算法决定的。 最基本的，算法需要知道容器元素的类型T。 算法可能需要获取容器元素类型的引用，获知其是否可以修改。迭代器要提供。 算法可能需要获取容器元素类型的指针，迭代器要提供。 算法需要在容器元素之间移动，所以迭代器需要提供在容器元素之间移动的方式。比如++，–，+n，-n等。 等等。。。 STL设计者归纳起来，作为迭代器，需要记录容器的五种信息，这五个信息作为迭代器的属性： value_type: 迭代器所指对象之类型，一般可以直接理解为容器元素的类型。 different_type: 两个迭代器之间的距离类型。 reference_type: 迭代器是const还是非const，表征是否可在相应容器元素上做修改。 pointer_type: 迭代器所指对象的指针类型。 iterator_category: 反映迭代器的移动特性和实施操作。比如最基本的++行为在不同容器的迭代器是不同的。（STL设计者在此做了很多巧妙的设计） 12345678910// std::iteratortemplate &lt;class Category, class T, class Distance = ptrdiff_t, class Pointer = T*, class Reference = T&amp;&gt;struct iterator &#123; typedef Category iterator_category; typedef T value_type; typedef Distance difference_type; typedef Pointer pointer; typedef Reference reference;&#125;; 此外，迭代器还要记录容器的操作方式和移动方式，这有点想智能指针。比如： operator* operator-&gt; operator++ operator-- 也就是说，如果一个独立设计的容器能够提供符合其特点、同时满足上述定义的迭代器，那么这个容器就能加入到STL算法的大家庭中。 4 迭代器设计的工作针对特定的容器，设计迭代器所要做的工作就是分析并精确定义前面描述五种类型，以及各种操作，比如operator++，operator–,operator-&gt;,operator*等等。 比如，容器list的迭代器12345678910111213141516171819202122template &lt;class T, class Ref, class Ptr&gt;struct list_iterator &#123; //五种迭代器的属性，使用内嵌类型的方式声明，用于萃取 typedef bidirectional_iterator_tag iterator_category; typedef T value_type; typedef Ptr pointer; typedef Ref reference; typedef ptrdiff_t difference_type; // 各种移动方式和操作方式 bool operator==(const self&amp; x) const &#123; return node == x.node; &#125; // 类似指针比较 bool operator!=(const self&amp; x) const &#123; return node != x.node; &#125; // reference operator*() const &#123; return (*node).data; &#125; //迭代器取值，取的是节点的值 pointer operator-&gt;() const &#123; return &amp;(operator*()); &#125; self&amp; operator++() &#123;&#125; //前置++ self operator++(int n) &#123;&#125; //后置++ self&amp; operator--() &#123;&#125; //前置-- self operator--(int n) &#123;&#125; //后置--&#125;; 另外，因为原生指针T*满足vector迭代器该有的属性，所以vector的迭代器直接使用T*12345template &lt;class T, class Alloc = alloc&gt;class vector &#123;public: typedef T* iterator;&#125;; 5 算法怎么获取迭代器的属性STL设计者使用了一种很巧妙的方法：内嵌型别 + iterator_traits萃取。 内嵌性别指的是：直接在迭代器类的内部声明五种属性的类型（见前面list）。 iterator_traits萃取即：123456789template &lt;class Iterator&gt;struct iterator_traits&#123; typedef typename Iterator::iterator_category iterator_category; typedef typename Iterator::value_type value_type; typedef typename Iterator::difference_type difference_type; typedef typename Iterator::pointer pointer; typedef typename Iterator::reference reference;&#125;; iterator_traits是个模板类，通过模板参数（迭代器的类型）Iterator，萃取出迭代器的五种属性。而算法根据萃取出来的五种属性类型，而选择不同的策略。 比如：根据萃取出来的距离类型声明返回值类型123456template&lt;class Iterator&gt;typename iterator_traits&lt;Iterator&gt;::difference_typedistance(Iterator first, Iterator last)&#123; typedef typename iterator_traits&lt;Iterator&gt;::iterator_category iterator_category; return _distance(first, last, iterator_category());&#125; 然而，问题来了，像vector这种直接把原生指针T*作为迭代器，并没有专门设计一个vector_iterator类，并在类内内嵌各种声明blablabla。怎么办？ 答案：模板偏特化 比如，为原生指针而设计的traits偏特化版123456789template &lt;class T&gt;struct iterator_traits&lt;T*&gt;&#123; typedef random_access_iterator_tag iterator_category; typedef T value_type; typedef ptrdiff_t difference_type; typedef T* pointer; typedef T&amp; reference;&#125;; 我们也要为const T*设计偏特化版本。具体可参考侯捷《STL源码剖析》 讨论到此，我们对迭代器为何存在于STL中有了一定的认识。要深入认识，可以阅读源码。 本文完。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>STL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从几个维度认识Linux进程]]></title>
    <url>%2F2018%2F05%2F21%2F2018-5-21Linux_Process%2F</url>
    <content type="text"><![CDATA[本文关注Linux进程]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux内核——等待队列浅谈]]></title>
    <url>%2F2018%2F05%2F19%2F2018_5_19LinuxKernel_WaitQueue%2F</url>
    <content type="text"><![CDATA[本文关注内容：Linux内核的一种数据结构：等待队列。在这里，我们不太去关注等待队列细节的实现。主要从功能角度谈下等待队列在内核中的角色。我的观点是，不管是内核，还是内核中的某个组件，理解其角色定位很重要，单纯是从实现细节上去理解某种机制，或许少了点乐趣。 你理解阻塞吗？写程序的时候，我们常常说某个系统调用是阻塞调用。从用户层的角度，基本理解是：进程在执行某个系统调用的时候，因为需要的资源不满足（IO操作，加锁等等），导致进程“停”在那里。等到资源就绪了或者设置的timeout时间超时了，进程得以继续执行。 从内核的角度，面对用户层对阻塞调用的需求，需要实现哪些机制呢？ 1.首先，进程陷入内核，内核发现进程所要求的资源暂时无法满足，需要将其设置为睡眠状态，然后调度其他进程执行。这里引出一个问题：（1）内核如何将一个进程睡眠？ 2.再来，等待资源就绪时，我们需要唤醒等待在该资源上面的进程。这里存在两个问题：（2）内核是怎么知道资源就绪的？以及，（3）某个资源就绪了，内核怎么找到对应等待的进程的？ 示例： 我们希望对某个socket fd进行阻塞write操作。发起写操作的时候，陷入内核，内核发现该socket fd的写缓冲区是满的，暂时不能写。这时，内核将进程设置为睡眠。 调用其他进程执行。等到该写缓冲区可以写的时候，内核将进程设置为执行状态，然后执行写操作，拷贝数据到内核写缓冲区。执行完，切换回用户态。 问题一：内核如何将一个进程睡眠 进程的task_struct结构有一个状态成员。将其设置为“睡眠”，并将task_struct结构从就绪队列中移走，内核就不会调度其执行，也就相当于睡眠。 问题二：内核怎么知道资源就绪的 中断。内核的所有的工作都是由中断驱动的。不管是系统调用陷入内核，还是调度，还是其他的内核活动，都是由各种各样的中断来触发执行的。对于设备IO，如果设备空闲了，会触发一个外部中断，该中断触发内核执行处理程序，通知等待进程、执行回调等等。 问题三：资源就绪了，内核怎么找到对应等待的进程 答案是等待队列。我们将一个资源和一个等待队列关联起来。如果进程所请求的资源还未就绪，就先加入到该资源的等待队列中。等到资源就绪了，就唤醒等待队列中的进程，加入到调度。 何为等待队列等待队列就是一个普通的双向链表，该链表的每个节点都代表一个进程task_struct的封装。每个资源都会有相应的等待队列。 等待队列与“惊群”“惊群”的基本行为是：有多个进程或者线程等待在同一个资源上，而且该资源一次只能有一个进程处理，比如文件描述符的写操作，accept一个新连接等。那么在资源就绪的时候。如果内核采取的策略是唤醒所有的进程。这样，只有一个进程获取了该资源，其他进程发现没有资源就绪，继续进入睡眠（所谓虚假唤醒）。这样的行为浪费了系统的CPU资源。 那是不是，内核在资源就绪的时候，就唤醒一个进程不就得了。其实也不是，因为不是所有资源都是互斥的。比如，某个文件的读操作。 那么，惊群问题怎么解决？ 在用户态，可以有不同的解决方式。或者忽略惊群所带来的开销，或者使用锁方式保证一次只有一个进程来阻塞在一个资源上。而对于内核来说，在等待队列上增加了一个是否“互斥等待”的标志。 如果是互斥等待的，一次唤醒一个进程。如果不是互斥等待的，一次唤醒所有进程。 互斥等待的经典例子：accept。因为我们很明确知道，对一个listen fd的accept,肯定是一次只有一个进程可以处理。那么，我们在listen fd上的等待队列，就毫无疑问可以设置为“互斥等待”。所以，现今版本的linux内核，解决了accept的惊群问题。 但是像epoll_wait的惊群问题，就无法从等待队列的互斥等待来解决。首先，epoll fd上也有一个等待队列，代表epoll fd所监听的其他若干文件描述符（资源）就绪时，唤醒等待队列上的资源。因为我们无法确定，这些资源是不是都是互斥访问的，还是都不是。所以，只好唤醒所有进程。更多的惊群问题，可以查阅相关资料。 总结等待队列是内核实现进程阻塞调用的机制。我们从概念上，浅谈了等待队列的用途，以及等待队列会出现的惊群问题。有说得不清楚的地方，还请见谅。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[进程环境]]></title>
    <url>%2F2018%2F05%2F18%2Fprocess_environment%2F</url>
    <content type="text"><![CDATA[讨论进程环境中几个点： 进程终止：exit和_exit的关系 环境变量的设置,putenv的陷阱 内存问题 longjmp的原理与陷阱 exit和_exit当一个进程正常终止时，系统需要做一系列的处理。这里涉及到两个层面：C库和内核的处理： C库层做的工作：刷新IO缓冲区，执行所有注册的退出函数； 内核层做的工作：回收进程所持有的一些资源； 进程正常退出时，先执行exit函数(C库层面)，再在exit函数里面调用_exit陷入内核，执行内核退出进程的操作。但异常退出又是怎么样的呢？异常退出只会执行内核退出进程的操作。 正常退出： main使用return；return(n)相当于exit(n); 直接使用exit(n) 异常退出： 使用_exit(n),因为没有正常执行C库层面的清理工作，所以我们把它归纳到异常状况。但是有时候_exit是必要的，比如多进程的时候。 信号中断。当出现信号中断，信号中断很多的处理都是进程终止，此时执行的直接是内核退出进程的操作，不会返回到C库执行清理工作。 exit1void exit(int status); exit()执行的动作： 调用注册的退出处理程序（通过atexit()和on_exit()注册的函数），其执行顺序与注册顺序相反（函数栈） 刷新stdio流缓冲区 使用由status提供的值执行_exit()系统调用。 _exit()1void _exit(int status); _exit()是系统调用，即其直接陷入内核，执行内核退出进程的操作（该操作无论是进程正常终止还是异常终止都会执行） 内核退出进程的操作 关闭文件描述符（释放任何文件锁），目录流 分离共享内存段 信号量 取消该进程调用mmap所创建的任何内存映射 等等。。。 使用atexit注册退出处理程序环境变量12int putenv(char *string);int setenv(const char * name, const char *value, int overwrite); 关键注意点： putenv直接使用的是string的内存空间，即需要保证string指向的变量长期存在，全局变量或动态内存等；setenv不存在这个问题，它会做相应的拷贝。 putenv参数形式，string的格式是“名字=值”；setenv参数分开 内存问题慎用realloc防止内存越界的几个新旧函数使用strncat替代strcat1char *strncat(char *dest, const char * src, size_t n); 从src中最多追加n个字符到dest字符串的后面。该函数自动追加‘\0’到dest的后面，所以n应该为dest可用空间减1。 使用strncpy代替strcpy1char *strncpy(char *dest, const char *src, size_t n); 从src中最多复制n个字符到dest字符串中。需要预留‘\0’的一个字节，并手动添加‘\0’。 使用snprintf代替sprintf12345678 int snprintf(char *src, size_t size, const char* format, ...);```c包含‘\0’，最多复制size个字符。**使用fgets代替gets**```c char *gets(char *str); char *fgets(char *s, int size, FILE *stream); gets函数从来不检查缓冲区的大小。fgets最多会复制size-1字节到缓冲区s中，并且会在最后一个字符后面自动追加‘\0’。 如何定位内存问题——Valgrind常见内存问题： 动态内存泄露:malloc,free 资源泄露，如文件描述符 动态内存越界 数组越界 动态内存double free 使用野指针 “长跳转”longjmpgoto是在函数内部实现短跳转，要实现跨函数跳转，得使用长跳转longjmp。 longjmp的原理和进程切换、信号中断返回的思想类似，要想实现非正常执行流的跳转，就需要进程在某一时刻的上下文。只要有进程上下文，将其装填到寄存器中，就能够实现跳转。12int setjmp(jmp_buf env);void longjmp(jmp_buf env, int val); setjmp使用jmp_buf结构体保存调用时刻的进程上下文，此结构变量需保证在longjmp时时存在的。 setjmp返回0时，为直接返回结果；返回非0值，为longjmp恢复栈空间返回的结果。 跳转一次之后，env保存的上下文就失效了。 longjmp的陷阱长跳转的实现原理是对与栈相关的寄存器的保存和恢复。 全局变量和static变量 保存在静态存储区，所以longjmp之后不会改变，不影响； 局部变量 满足一下条件的局部变量的值是不不确定的 调用setjmp所在函数的局部变量 其值在setjmp和longjmp之间有变化 没有被声明为volatile变量 C++析构函数 调用longjmp之后，没有正常解栈，本该调用的析构函数没有调用。如：12345678void func()&#123; Test test; longjmp(g_stack_env);&#125;/* 对象test的析构函数没有调用。*/]]></content>
      <categories>
        <category>操作系统</category>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux文件IO]]></title>
    <url>%2F2018%2F05%2F18%2Flinux%E6%96%87%E4%BB%B6IO%2F</url>
    <content type="text"><![CDATA[文件描述符和句柄句柄，从一般意义上讲，句柄作为内核与用户的交互。用户无法指定内核对象的本体，内核可以提供一个整数值，在内核创建内核对象的时候，返回给用户。用户在想调用该对象的时候，可以指定。 例如，文件在内核的活动对象是一个个file结构，对于用户来说，文件描述符代表这一个文件的标识。用户可以指定文件描述符，内核通过查找来找到文件管理结构file. 因此，文件描述符可以称为“文件句柄”。 内核文件表每个进程管理一张打开文件表，用以管理当前进程所打开的文件，称为“进程打开文件表”，保存在task_struct-&gt;files字段，是一个files_struct结构体。 files_struct结构的功能是管理一个file结构指针数组，文件描述符就是用来索引该数组，从而找到真正的文件管理结构file.此外，files_struct的两个重要字段： close_on_exec_init: 表示当执行exec时要关闭的文件描述符位图 open_fds_init: 保存打开的文件描述符位图 文件管理结构file123456789struct file &#123; /*...*/ const struct file_operations *f_op; 与该文件相关联的操作函数 atomic_t f_count; 文件的引用计数(有多少进程打开该文件) unsigned int f_flags; 对应于open时指定的flag mode_t f_mode; 读写模式：open的mod_t mode参数 off_t f_pos; 该文件在当前进程中的文件偏移量 /*...*/&#125;; 文件操作open操作打开一个文件，内核都做了些什么呢？ 在进程打开文件表中找到一个未使用的文件描述符 申请一个新的文件管理结构file,根据不同的打开标志和mode产生不同的行为和file结构。 绑定文件描述符和对应的文件管理结构file，把文件描述符返回给用户。 可见，open操作，内核主要消耗两种资源：文件描述符和文件管理结构file。 open参数 pathname : 文件路径 flags: 打开标志 mode：文件的权限位，只在创建文件时需要，并受到umask的影响。 每一次open操作,都将分配一个文件描述符和文件管理结构,即使打开的是同一个文件. close操作close用于关闭文件描述符。而文件描述符可以是普通文件，也可以是设备，还可以是socket.在关闭时，VFS会根据不同的文件类型，执行不同的操作。这个实现机制由file结构的fop字段绑定的具体操作函数实现。 遗忘close造成的问题 文件描述符没有释放 文件管理结构没有释放 对于普通进程，在进程结束时，内核自动回收；但是对于常驻进程，问题相当严重。 如何查找文件资源泄露——lsof命令 文件偏移文件偏移量是打开文件中比较重要的属性.它代表当前进程对当前打开文件的读写位置.一般情况下,读写操作都是从当前的偏移位置开始读写, 并且在读写结束之后更新偏移量. 刚打开文件时, 文件偏移量为0; 进程fork之后,父子进程的对同一打开文件的文件偏移量是一样的吗?后面解答. 读文件_read1ssize_t read(int fd, void* buf, size_t count); 最一般意义,read尝试从fd中读取count个字节到用户定义缓冲区buf中,并返回实际成功读取的字节数. 意外情况:返回值为-1 errno = EAGAIN, EWOULDBLOCK: fd为非阻塞且没有数据可返回时 errno = EINTR: 信号中断 部分读取 不同类型的文件出现部分读取的情况是不同的,根据具体绑定的fops-&gt;read函数而定: 普通文件,到达文件末尾 EOF socket文件系统的UDP: UDP报文数据长度小于参数len时,返回实际的数据长度 …(根据不同的类型小心处理) 写文件_write1ssize_t write(int fd, const void*buf, size_t count); write操作根据当前fd的文件偏移量, 写入count个字节数据.与read操作类似,同样会出现部分写的情况. 追加写–O_APPEND 当使用O_APPEND以追加的形式打开文件的时候,每次写操作都会先定位到文件的末尾,然后再执行写操作.每次写操作获取到的都是文件(inode)的最新末尾位置(对inode加锁保护, 以避免多进程情况下竞争). 文件描述符的复制123int dup(int oldfd);int dup2(int oldfd, int newfd);int dup3(int oldfd, int newfd, int flags); dup:使用一个最小的未使用的文件描述符作为复制后的文件描述符 dup2:使用用户指定的newfd来复制oldfd,如果newfd已经打开,就先关闭newfd,在复制oldfd(close+dup的原子性调用) dup3:支持O_CLOEXEC.表示新复制的fd在fork并执行exec之后,将关闭. 复制的只是文件描述符 新复制的文件描述符和旧的文件描述符指向的是同一个file文件管理结构,他们共享文件偏移量,文件读写模式,文件打开标志等等. file的创建仅仅在open操作的时候发生. 文件同步文件截断进程执行fork后，文件打开表和文件管理结构file]]></content>
      <categories>
        <category>操作系统</category>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[管道——花园软水管]]></title>
    <url>%2F2018%2F05%2F18%2Flinux_ipc_pipe%2F</url>
    <content type="text"><![CDATA[一、小谈管道历史关于管道，有这么一句话： 如果说Unix是计算机文明中最伟大的发明，那么，Unix下的Pipe管道就是跟随Unix所带来的另 一个伟大的发明。 管道的出现就是为了使软件开发更加“高内聚，低耦合”。管道的发明者，Malcolm Douglas McIlroy，同时也是Unix创建者及Unix文化缔造者，他的Unix哲学： 程序应该只关注一个目标，并尽可能把它做好。让程序能够互相协同工作。应该让程序处理文本 数据流，因为这是一个通用的接口。 也就是说，管道存在的意义就是让程序能够专注自己的目标，而不同进程之间可以相互通信协作，完成一个更大的目标。比如：在主机上，客户进程可以通过管道给文件服务器进程发送文件名，文件服务器打开文件然后将文件数据通过管道传给客户进程，如此，客户进程和文件服务器相互独立，同时相互协作。这其实不仅仅是管道的特点，同时也是其他进程间通信（IPC）手段的特点。不同的IPC实现各有不同，但是目的、哲学道理都是差不多的。 IPC技术：管道，共享内存，消息队列，信号量，本地套接字等。 管道一般是单向的，半双工的，像花园的软水管，一边进一边出。要想实现全双工，一般需要两条管道。 二、管道基本实现每个进程都有自己的独立的地址空间，要想实现进程之间的相互通信，必须采取必要的手段: 共享内存或者借助内核。管道的实现就是借助内核。 管道的本质就是内核维护的一段内存。因为linux“一切皆文件”的思想，管道自然而然就被实现为“管道文件”（向普通文件一样管理），隶属管道文件系统pipefs。因此，和普通文件一样，内核负责维护文件的细节，返回给用户进程的只是一个个“文件描述符”，通过文件描述符，进程可以执行打开管道、读写管道的操作。 管道分为两种：无名管道pipe和有名管道FIFO 无名管道pipe 何为无名管道？无名管道就是用户进程只能通过文件描述符fd才能找到的管道，内核没有给其他方式告诉管道在哪里。即没有名字，只有句柄（文件描述符）。一般来讲，文件描述符只会在有亲缘关系的进程间继承，这就限制了无名管道一般只用在有亲缘关系进程间通信。 有名管道FIFO 何为有名管道？有名管道，对比无名管道，它跟实体文件名绑定。任何进程只要知道跟管道绑定的文件名，就可以尝试打开管道并操作。这意味着，有名管道可以使用在没有亲缘关系的进程间通信使用。 三、无名管道pipe创建无名管道pipe12345678//原型 int pipe(int fd[2]);//例子 int pipefd[2]; int error = pipe(pipefd); //调用成功，返回两个文件描述符， 管道只读端pipefd[0]和管道只写端pipefd[1]; 无名管道使用（搭配进程fork）无名管道因其只以文件描述符索引，所以一般的使用方式： 某个祖先进程（父进程）先创建管道，然后fork出若干子进程，父子进程或兄弟进程之间通过继承得到 的管道文件描述符来读写管道，从而达到通信的目的。 12345678910111213141516171819202122//Example: int pipefd[2]; pid_t childpid; pipe(pipefd); if((childpid = fork()) == 0) &#123; //子进程 //关闭管道读端或写端描述符 //write or read exit(0); &#125; else if(childpid &gt; 0)&#123; //父进程 //关闭管道写端或读端描述符 // read or write // waitpid() &#125; else &#123; //fork error &#125; 注意点 ：管道的双方要关闭不需要使用到的文件描述符，为什么？这涉及管道读取端如何判断对方已经不再写了？管道写端进程如何判断管道另一头已经没有进程在读了？ 当读取端已无进程等待（即fd[0]的引用计数为0 （close））, 此时若有进程对写端继续写，返回EPIPE错误。并产生信号SIGPIPE。 当写端已无进程再继续写（即fd[1]的引用计数为0 （close））, 若管道的数据读完，将返回文件结束符EOF。 因此，为了能够正常判断结束条件，进程要关闭其没有使用的管道文件描述符。 无名管道是不是只能用在用亲缘关系的进程中？ 答案是否定的。因为借助本地套接字，可以在进程间传递文件描述符。 popen/pclose123#include &lt;stdio.h&gt;FILE *popen(const char* command, const char *type);int pclose(FILE *stream); popen行为：fork并执行shell进程，shell进程fork并执行command进程，并返回文件描述符。该文件描述符fd或为读端（管道写端关联到command进程的标准输出），或为写端（管道读端关联到command进程的标准输入）。这取决与popen是以读模式还是以写模式打开。 四、命名管道FIFO创建管道123int mkfifo(const char* path, mode_t mode);// 成功，创建一个新的FIFO// 返回EEXIST错误（指定文件名的FIFO已经存在） 参数： path: 文件路径名 mode: 文件权限位 创建管道用mkfifo，打开管道用open 调用mkfifo成功创建管道后，其他进程可以通过open相应的“文件名”从而获取管道，进行读或写。 五、管道属性管道的打开行为、读写行为管道open和O_NONBLOCK管道默认是阻塞的。和普通文件描述符一样，任何时候可以通过fcntl（瑞士军刀）设置成非阻塞。 管道阻塞， open + O_RDONLY : 此时没有进程为写打开，则阻塞。 管道阻塞， open + O_WRONLY ：此时没有进程为读打开，则阻塞。 管道非阻塞， open + O_RDONLY : 无论有没有进程为写打开，立即返回。 管道非阻塞， open + O_WRONLY ： 没有读进程，则返回-1，errno = ENXIO。 管道读写 阻塞、空管道或FIFO，read：有写进程，阻塞到有数据；无写进程，返回EOF； 非阻塞、空管道或FIFO，read: 有写进程，返回EAGAIN；无写进程，返回EOF； 阻塞、管道或FIFO，write: 有读进程，见下文；无读进程，返回SIGPIPE； 非阻塞、管道或FIFO，write: 有读进程，见下文；无读进程，返回SIGPIPE； 管道写行为、PIPEBUF、原子性管道有一特点，尽力保证写入的原子性： 如果请求写入的数据字节数小于等于PIPE_BUF，那么write操作保证是原子的。大于PIPE_BUF，则不保证。 如此，在非阻塞情况下： 请求写入字节数小于等于PIPE_BUF: 当前管道空间足够，则直接写入； 当前管道空间不够，为保证原子性，先返回EAGAIN，告诉进程稍后尝试； 请求写入字节数大于PIPE_BUF： 当前管道空间至少还有1字节，直接写相应字节数，返回； 当前管道满，返回EAGAIN。 PIPE_BUF的大小可以通过fcntl来设置。 从上面的讨论可以看出，管道的读写需要一些技巧。所谓“管道有大小，写入需谨慎”。 一次写入数据量不超过PIPE_BUF，以保证写入是原子的。即使存在多个进程同时读，也不会被打断。 写端不要大量输入，会造成阻塞。 读端，要及时读取，避免造成写入阻塞。]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[inline函数]]></title>
    <url>%2F2018%2F05%2F18%2Finline%2F</url>
    <content type="text"><![CDATA[引子程序1234567891011121314// file.ccinline void foo(void)&#123; /*函数体*/&#125;// file.hvoid foo(void);// main.ccint main()&#123; foo();&#125; 上面的编码会出现什么问题? 链接错误,显示foo未定义(undefined reference to `foo()’). 编译器对inline函数的处理使用inline函数,意图是在函数调用处直接替换成函数体,省去函数调用,提高函数的执行效率.但编译器在处理的时候,真正的处理流程是什么样的呢? 我们知道,c/c++程序编译分为几个阶段,预处理-&gt;编译+汇编-&gt;链接.inline的处理阶段发生在编译阶段.也就是说,在编译阶段完成后,目标模块的inline函数要么被替换了,要么没有被替换,但是链接时可以找到inline函数的定义.也就是说,在编译阶段之前,目标模块需要看到inline函数的实现. 拿引子程序来说,编译main.o目标模块时,编译器”看到”了foo的声明,此时它并不知道foo是要inline的.编译file.o目标模块时,编译器看到foo的实现,并且声明为inline,由于foo在file.o没有被使用到,所以,inline函数不被保留.链接的时候,当然也就找不到foo的定义实体了.针对此例子,我们可以在file.c定义一处函数,使用了一次foo(),编译就可以通过.12345//file.ccint foo2()&#123; foo();&#125; 正确的做法是,inline函数的实现(定义)要跟随其函数声明放在.h文件中.编译器在编译阶段就可以看见函数实现,从而进行替换.(这一点有点向函数模板,函数模板也是要放在声明文件中,不能单独放在源文件中) inline和宏的区别 1.宏define在预处理阶段完成；inline在编译阶段完成； 2.类型安全检查，inline是函数，需要做类型检查； 3.替换方式：宏是字符串拷贝替换，会出现边际效应；inline是嵌入代码，在编译过程中不单独产生代码。 4.宏不可调试，inline函数可以调试。这里的“调试”之意是指在程序的debug版本是没有内联的，编译器会生成像普通函数一样含有调试信息的可执行代码。在release版本，才实现真正的内联。 5.inline函数可以操作私有数据成员。 内联函数的使用inline函数的编程风格关键字inline必须与函数定义放在一起才能使函数真正内联,仅把inlilne放在函数声明的前面不起任何作用.12345678910111213//Foo不能内联inline void Foo(int x, int y);void Foo(int x, int y)&#123; ...&#125;//Foo内联void Foo(int x, int y);inline Foo(int x, int y)&#123; ...&#125; inline是一种”用于实现的关键字”,而不是一种”用于声明的关键字”. 慎用内联 如果函数体内的代码过长,使用内联将导致可执行代码膨胀过大 如果函数体内的代码出现循环或者其他复杂的控制结构,那么执行函数体内代码的时间比函数调用的开销大得多,因此内联的意义不大. 不要轻易让构造函数和析构函数成为内联函数inline仅仅是对编译器的一种请求,编译器可以无视inline常跟static一起当多个源文件包含同一个inline函数，但是编译器又无视inline请求，如此一来，在每个目标模块中都有该函数的实现实例，造成重定义错误。把inline函数同时声明为static函数（限制其作用域为源文件内部），可以解决问题。]]></content>
      <categories>
        <category>编程语言</category>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo Start]]></title>
    <url>%2F2018%2F05%2F18%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[非阻塞式IO]]></title>
    <url>%2F2018%2F05%2F18%2FNB_IO%2F</url>
    <content type="text"><![CDATA[一、概述阻塞与非阻塞的概念在用户进程或者线程进行系统调用进入内核的时候，如果不能马上满足条件，内核对调用者采取不同的行为，分为“阻塞”和”非阻塞“两种。”阻塞“表示如果系统调用不能马上获得满足而返回，就将调用者（进程或线程）挂起，等到满足条件，内核执行完系统调用，重新恢复调用者。”非阻塞“表示如果系统调用不能满足，则立即返回，并设置错误信息以告知调用者，该系统调用因何不能满足。 从以上看，”阻塞“虽然使用比较简单，但是很被动，会出现”永久阻塞“而导致无法处理的问题，设想一下，客户端进程阻塞等待接受服务器的消息，但是这个服务器因为某种原因崩溃了，如此客户端就会永久阻塞。相反，”非阻塞“技术给了程序员更大的灵活性，只要能够合理处理各种情况便能够更好的提高效率。 总之，非阻塞调用相对与阻塞调用有几个好处: 不会出现“永久阻塞”（设置超时也可解决永久阻塞问题） 同时监听多个IO复用的程序模型，如果使用阻塞调用，可能出现顾此失彼的情况。即，系统调用阻塞在某个IO上时，可能有另一个IO已经就绪，而它不能被及时响应。 也因为如此，使用非阻塞技术要体现这些优势。 网络编程背景下的非阻塞式IO可能阻塞的套接字调用分为以下四类： 输入操作（read、readv、recv、recvfrom、recvmsg五个函数） 输出操作(write、writev、send、sendto、sendmsg五个函数) 接受外来连接，accept函数 发起外出连接，用于TCP的connect函数 二、非阻塞读和写UNP给出一个数据，echo服务下的客户端不同版本str_cli函数，测试从一个Solaris客户主机想RTT为175毫秒的一个服务器主机复制2000行文本，所花时间的不同： 354.0s，停等版本 12.3s，select+阻塞式IO版本 6.9s, select+非阻塞IO版本 8.7s, fork版本（多进程） 8.5s，多线程版本从这个数据可以看出： 一、IO复用模型的使用确实大大加快了IO的处理 二、IO复用模型搭配非阻塞技术可以再提高效率（但是会提高编程的复杂性） UNP推荐：相对于select+非阻塞IO，最好使用效率差不多、但是编程更简单的多进程模型。 对UNP书上str_cli函数的select+非阻塞式IO的注解本版本需要做的工作： 维护两个缓冲区; 使用selectIO复用，监听并处理四个IO; 对所有监听的IO都设置成非阻塞IO; 恰当处理终止条件，当服务器终止连接或者客户端标准输入得到EOF; 动态性强，但是编程要考虑的情况多。UNP提供了效率差不多，但是编程简单的fork版本。该版本做的工作较少： fork出子进程，负责阻塞等待套接字可读，并将收到的消息输出到标准输出； 父进程负责阻塞等待标准输入可读，并将收到的消息写入套接字； 三、非阻塞connect]]></content>
      <categories>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux进程和线程]]></title>
    <url>%2F2018%2F05%2F18%2FLinux%E8%BF%9B%E7%A8%8B%E5%92%8C%E7%BA%BF%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[问题 Linux系统中，进程和线程的区别？ Linux系统中，进程和线程的效率差别大不大，如何验证？]]></content>
      <categories>
        <category>操作系统</category>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++数组名和指针的关系]]></title>
    <url>%2F2018%2F05%2F18%2FC%E6%95%B0%E7%BB%84%E5%90%8D%E9%80%80%E5%8C%96%E4%B8%BA%E6%8C%87%E9%92%88%2F</url>
    <content type="text"><![CDATA[数组名不是指针！！！ 数组名指代的是数组整个实体结构。 数组名可以外延成指代实体的指针，而且是一个指针常量。 指向数组的指针，仅仅是数组第一个元素的地址。 a[i]内部翻译为*(a+i) 对数组名取地址，&amp;array+1,其步长是整个数组，与&amp;(array+1),步长是一个数组元素不同 数组名退化为指针在形参为数组的情况下，数组名会退化为指针，在函数内部，实际上是一个指针。1234void foo(int array[])&#123; cout &lt;&lt; sizeof(array) &lt;&lt; endl; //输出为8，为一指针大小，不是数组的大小&#125; sizeof是个操作符，不是函数sizeof操作符：求得是对象或类型的大小，这里的“大小”指的是“所占内存空间的实际大小”。 数组名代表的是整个数组结构实体，所以求得的是整个数组实体的内存大小。 指针结构实体本身，表示“一个指针结构”占用的内存大小，64位系统为8字节。 12345int array[10]; sizeof(array); // 4 * 10 = 40字节int * p;sizeof(p); // 8字节]]></content>
      <categories>
        <category>编程语言</category>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高级IO函数]]></title>
    <url>%2F2018%2F05%2F18%2FAdvance_IO_Func%2F</url>
    <content type="text"><![CDATA[一、概述讨论几个问题： 为避免函数调用不可预期的永久阻塞，可以对IO操作设置超时，设置超时有哪些方法？ 最基本的读写函数read/write，及其各种变体（send, recv, recvmsg….）是什么样的关系？ 如果仅仅想查看套接字接收缓冲区的数据而不读取，要怎么做？ 二、为套接字设置超时抛出各种具体方法： 信号中断：alarm函数 + SIGALRM信号（缺点:干扰程序正常alarm的使用，在多线程程序中使用信号很困难） select保安：利用select可以设置超时，让select代为阻塞等待在IO上。 套接字选项：SO_RCVTIMEO和SO_SNDTIMEO（不能用于connect设置超时） 三、读写函数的各种变体基本read/write及其三种变体send/recv、readv/writev和recvmsg/sendmsg 简要对比： send/recv对比read/write多了一个flags参数，可以传给内核； readv/writev对比read/write，后者是单个缓冲区的读写，前者则可以支持在单个系统调用中实现多个缓冲区的读写，称为“分散读”和“集中写”。 recvmsg/sendmsg是最通用的函数，它集中了前面集中的所有特性。但是这组只能在套接字描述符中使用。 sendto/recvfrom一般只在UDP套接字中使用。 send/recv123#include &lt;sys/socket.h&gt;ssize_t recv(int sockfd, void* buff, size_t bytes, int flags);ssize_t send(int sockfd, const void* buff, size_t bytes, int flags); flags——值参数 MSG_DONTROUTE: 发送操作无须路由，仅限发送操作。表示目的主机在某个直接连接的本地网络上。 MSG_DONTWAIT：单次操作“非阻塞”。 MSG_OOB:对于send,表示即将发送的数据是带外数据（对于TCP只有一个字节）；对于recv表示，即将读入的是带外数据而不是普通数据。 MSG_PEEK:表示仅查看可读取的数据，不作读取。适用于recv和recvmsg。 MSG_WAITALL:表示尚未读到请求数目的字节之前不让一个读操作返回。意外情况:a. 捕获一个信号；b.连接被终止；c.套接字发生错误，相应的读函数仍旧可能返回少于请求数目的数据。 readv/writev12345678#include &lt;sys/io.h&gt;ssize_t readv(int flags, const struct iovec *iov, int iovcnt);ssize_t writev(int flags, const struct iovec *iov, int iovcnt);struct iovec &#123; void *iov_base; //缓冲区起始地址 void *iov_len; //缓冲区长度&#125;; 注： writev是原子调用，对于数据报协议，一次writev调用只会产生一个UDP数据报。 writev的一个用途：将小包数据经过整合，使用writev发送，可以有效防止Nagle算法的触发。 recvmsg/sendmsg具体参见UNP14.6 四、获悉已排队的数据量方法： 如果获悉已排队数据量的目的在于不想阻塞，那么可以使用非阻塞调用。 如果既想查看数据，有想保留数据在接收队列中以供本进程其他部分稍后读取，可以使用MSG_PEEK。通常需要结合非阻塞+PEEK，要么是非阻塞套接字+MSG_PEEK,或者阻塞+MSG_DONTWAIT+MSG_PEEK。对于TCP，先只“获悉”，再次“读取”，两次调用的返回数据长度可能是不同的；对于UDP，两次调用的返回数据是完全相同的。 ioctl + FIONREAD, 通过第三个参数（值——结果）返回当前接收队列的字节数。]]></content>
      <categories>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11——理解右值]]></title>
    <url>%2F2018%2F05%2F17%2F2018-3-6rvalue%2F</url>
    <content type="text"><![CDATA[概述本文关注内容：右值和右值引用，以及移动语义、完美转发。 发现身边的右值学习右值之所以会觉得很晦涩难懂，是因为我们完全习惯使用了左值。就像突然哪天告诉你，有“暗物质”的存在，你的“常识世界”是一下子不能接受的。 变量（或者说对象）可以看作是内存中的一小段。程序不断运行达到某种功能都是对若干个位于内存的对象，不断加工、修改的，各个对象又相互联系的结果。 在编程过程中，我们会定义各种变量：1234567int i = 0;class ObjectA &#123; ObejctA() &#123;&#125;;&#125;;ObjectA a(); 这些定义操作，编译器会这样做： 1.分配一段内存，命名为i，内存大小按照int类型标准分配，然后这段内存初始化为0； 2.分配一段内存，命名为a，内存大小按照ObjectA类型标准分配，然后这段内存根据默认构造函数初始化。这样，在程序的其他地方，我们可以使用变量名i或者a，来达到修改它们所代表的内存的目的。比如：1i = 1; 这就是左值。它们是可以取地址的。它们会有个名字，就像门牌号。程序员可以明确地说：我就要使用某某地址上的那个变量i，我要把它改成1。 那么，内存世界里，除了程序员明确定义的变量占据内存，是否还存在其他构建了的内存对象？答案是有的。在程序编译期间和运行期间，会在内存构造很多没有名字的对象（匿名对象），它们有的为了计算，有的为了支持上层的语言特性。看以下几种情景：1int i = GetValue(); 运行过程：程序通过GetValue()计算得出一个“结果”，然后将这个结果拷贝到i所命名的内存位置。我们考察这个“结果”（临时值），它同样需要一个和i一样的内存，只是在拷贝给i之后，这段内存就销毁了。 123456789101112131415161718struct ObjectA&#123; ObjectA()&#123; cout &lt;&lt; "Constructor" &lt;&lt; endl; &#125; ObjectA(const ObjectA&amp; ) &#123; cout &lt;&lt; "Copy constructor" &lt;&lt; endl; &#125; ~ObjectA() &#123; cout &lt;&lt; "Destructor" &lt;&lt; endl; &#125;&#125;;int main()&#123; ObjectA a = ObjectA();&#125; 使用-fno-elide-constructors来取消返回值优化，以便观察临时值的产生。运行结果： Constructor Copy constructor Destructor Destructor 可以看出，这里构造了一个临时对象，然后拷贝给a之后，临时对象就销毁了。 此外，lambda表达式也属于右值，它们在内存中也会以某种对象的形式存在，但是你无法知悉它们的存储位置（获取地址）。 知道右值的存在，我们如何使用右值？答案：右值引用。 和左值引用一样，右值引用允许你直接引用匿名对象的那段内存，虽然你无法知悉它的地址，但不影响你使用。编译器使用&amp;&amp;符号表示右值引用。1ObjectA &amp;&amp;a = ObjectA(); //语义：直接把临时构造的对象返回给a，a作为这个临时对象的引用供程序员使用。 这里运行结果： Constructor Destructor 12auto f = []()&#123; return 1; &#125;; //lambda表达式（匿名表达式）可以使用一个右值引用去“承接”它。f(); //然后就可以使用这个右值引用，在其他地方调用这个lambda表达式 这里要区分好右值和右值引用。右值是一种对象的概念，而右值引用和左值引用一样，是引用。 使用右值，好处多多通过前面的描述我们可以看到，很多时候，匿名对象（临时对象）的构造是不为人所知的。很多情况下，匿名对象的生命周期很短。它们被构造，然后在短时间内又被销毁。如果构造对象涉及开销比较大的操作，比如malloc。 我们来看一个配备移动构造函数的类对象的例子。 12345678910111213141516171819202122232425//没有移动构造函数class ObjectA &#123;public: ObjectA() : m_ptr(new char[1]) &#123; cout &lt;&lt; "Constructor" &lt;&lt; endl; &#125; ObjectA(const ObjectA&amp; a) : m_ptr(new char[*a.m_ptr]) //深拷贝 &#123; cout &lt;&lt; "Copy Constructor" &lt;&lt; endl; &#125; ~ObjectA() &#123; delete[] m_ptr; cout &lt;&lt; "Destructor" &lt;&lt; endl; &#125;private: char* m_ptr;&#125;;int main()&#123; ObjectA a = ObjectA(); //产生临时对象，该条语句运行完，临时对象销毁&#125; Constructor Copy Constructor Destructor Destructor 临时对象分配了动态内存，然后短时间内又析构释放。为了定义一个对象，总共发生了两次的new操作。 12345678910111213141516//配备移动构造函数class ObjectA &#123; // .... ObjectA(const ObjectA&amp; a) : m_ptr(new char[*a.m_ptr]) &#123; cout &lt;&lt; "Copy Constructor" &lt;&lt; endl; &#125; //移动构造函数 ObjectA(ObjectA &amp;&amp; a) : m_ptr(a.m_ptr) &#123; // a.m_ptr = nullptr; cout &lt;&lt; "Move Constructor" &lt;&lt; endl; &#125; // ...&#125; Constructor Move Constructor Destructor Destructor 只发生一次new操作。我们将临时对象new的动态内存直接转移给了返回的对象。节省开销。 程序员明确知道，会产生临时变量，而且这个临时变量会在短时间内析构。那么何不将其捕捉，直接利用呢？移动构造函数就是利用这一点。 左值也可转化为右值——std::move()左值是一种对象的概念，右值也是一种对象的概念。说白了，就是内存嘛。那么，一个左值可以用右值的方式看待，从而使用到右值的一些便利呢。答案是可以。 比如，我明确清楚某个对象我不会再使用了，但是里面的资源释放掉蛮可惜的，我希望新的对象或者其他对象直接来承接这些资源。std::move()模板函数提供了这样的功能。 123456int main()&#123; ObjectA a = ObjectA(); ObjectA b(std::move(a)); //我们明确不会再使用a,就可以将其所只有的资源转移给新的对象。（具体转移操作由移动拷贝构造完成）&#125; 运行结果： Constructor Move Constructor Destructor move … Move Constructor Destructor Destructor 类似具有转移语义的函数还有移动赋值语句12345ObjectA&amp; operator=(ObjectA&amp;&amp; a) &#123; cout &lt;&lt; "operator= &amp;&amp;" &lt;&lt; endl; m_ptr = a.m_ptr; a.m_ptr = nullptr;&#125; 完美转发 –std::forward模板基本：一个&amp;&amp;的形参可以匹配左值，也可以匹配右值。&amp;&amp;称为universal reference。 需求：函数模板中，需要将参数转发给函数函数模板中调用的另一个函数。传入右值类型，转发的也要保留右值类型，传入左值类型，转发也要保留左值类型。 12345678910111213141516void process(int&amp; i) &#123; cout &lt;&lt; "lvalue call, i = " &lt;&lt; i &lt;&lt; endl; &#125;void process(int&amp;&amp; i) &#123; cout &lt;&lt; "rvalue call, i = " &lt;&lt; i &lt;&lt; endl; &#125;template &lt;typename T&gt;void func(T&amp;&amp; t)&#123; process(t); // t是右值引用，但t本身是左值，所以匹配到的是process(int&amp; i)&#125;int main()&#123; int a = 2; func(a); func(10); &#125; 运行结果： lvalue call, i = 2 lvalue call, i = 10 12345template &lt;typename T&gt;void func(T&amp;&amp; t)&#123; process(std::forward&lt;T&gt;(t)); // t是右值引用，但t本身是左值，所以匹配到的是process(int&amp; i)&#125; 运行结果： lvalue call, i = 2 rvalue call, i = 10 使用完美转发和移动语义来实现一个泛型的工厂函数，这个工厂函数可以创建所有类型的对象12345template &lt;typename... Args&gt;T* Instance(Args... args)&#123; return new T(std::forward&lt;Args&gt;(args)...);&#125; [TODO] std::move的实现 std::forward的实现]]></content>
      <tags>
        <tag>C/C++</tag>
        <tag>C++11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈Select、Poll与Epoll的实现区别]]></title>
    <url>%2F2018%2F05%2F03%2F2018-5-19Select_Poll_Epoll%2F</url>
    <content type="text"><![CDATA[本文关注内容：LinuxIO复用的三种机制，分别是Select、Poll以及Epoll。本文倾向于从浅谈三种机制的内核实现，来对比三种IO复用机制的性能差异。预备知识：等待队列和阻塞。 1 Select1.1 Select API12#include &lt;sys/select.h&gt;int select(int maxfdp1, fd_set *restrict readfds, fd_set* restrict writefds, fd_set* restrict exceptfds, struct timeval *restrict tvptr); 1.2 Select实现 1.内核使用copy_from_user从用户空间拷贝fd_set到内核空间 2.遍历所有关心的fd，如果fd就绪，就设置fd_set的值；如果fd不就绪，就将当前进程current加入到fd的等待队列（不休眠）。 3.当遍历完所有的fd后，发现有fd就绪，则直接返回。如果没有一个是就绪的，那么调用schedule出让CPU进入睡眠（如果设置有超时时间，则调用schedule_timeout）。当有fd就绪的时候，会唤醒其等待队列上的进程。进程获得唤醒，再去重新遍历所有fd，判断是否有fd就绪。 4.把fd_set从内核空间拷贝到用户空间。 1.3 Select的特点 1.每次调用select都要重新设置fd_set。缺点：浪费时间，影响性能。 2.调用select进入内核，或者从内核返回，都要拷贝一次fd集合。缺点：浪费时间，影响性能。 3.文件描述符用fd集合组织，支持的数量大少，默认是1024。 4.应用程序需要遍历整个fd_set，来获取哪些fd上的读写事件就绪。如果只有几个fd有就绪事件，遍历整个fd_set会造成极大的性能浪费。 2 Poll2.1 Poll API12345678#include &lt;poll.h&gt;int poll(struct pollfd *fds, nfds_t nfds, int timeout);struct pollfd &#123; int fd; short events; short revents;&#125;; 2.2 Poll实现内核实现基本和Select相同，只是有一点不同。从poll()函数的参数可以看出。文件描述符改用pollfd结构的数组组织，数量就比select多得多。 2.3 Poll特点 调用poll进入内核或者从内核返回，内核都要拷贝一次pollfd结构数组。缺点：浪费时间。 应用程序需要遍历整个pollfd结构数组，才能获取哪些fd有就绪事件。 3 EpollEpoll由Select、Poll发展而来。从Select、Poll的缺点来看，我们可以总结一下几个优化点: 1.Select、Poll每次调用都是一次独立的注册、收集、返回的过程，很低效。–&gt; Epoll将注册感兴趣事件和收集就绪事件分开。 2.Select、Poll每次需要拷贝事件集合fd_set或事件数组到内核，收集事件时再拷贝到用户空间。 –&gt; Epoll对同一个事件，只注册一次。 3.处理就绪事件，Select、Poll需要遍历整个fd_set或这pollfd结构数组。 –&gt; Epoll收集事件时只返回就绪的事件。 3.1 API12345678910111213141516171819#include &lt;sys/epoll.h&gt; int epoll_create(int size); // 初始化一个epfdint epoll_ctl(int epfd, int op, int fd, struct epoll_event* event); //添加、修改、删除感兴趣事件int epoll_wait(int epfd, struct epoll_event* events, int maxevents, int timeout); //一次事件收集typedef union epoll_data &#123; void *ptr; int fd; uint32_t u32; uint64_t u64;&#125; epoll_data_t;struct epoll_event &#123; uint32_t events; epoll_data_t data;&#125;; 3.2 Epoll实现epoll_create分配一个文件描述符以及对应的struct file结构。分配一个struct eventpoll结构用体于管理，在该结构体初始化红黑树头节点，初始化就绪链表，初始化等待队列等等。这个eventpoll结构是epoll的关键，它管理这一棵红黑树，一个就绪链表，一个等待队列等等。 红黑树：高效的插入和删除操作。用于在添加、修改、删除感兴趣事件。 就绪链表：存放已经就绪的事件。epoll_wait直接从这里拷贝事件返回用户。 等待队列：如果有多个进程等待在这个epfd上，则会加入到这个等待队列。 epoll_ctl+ add操作：分配一个与要监听的fd对应的epitem，并初始化相应的成员，然后插入到红黑树。并将当前进程current挂到对应fd的等待队列，并注册一个回调函数。该回调函数会在fd就绪时，将事件结构体加入到就绪队列中（这点有设备驱动触发中断完成）。epoll_ctl的删除操作和修改差不多。 epoll_wait直接查看就绪链表是否为空，如果不为空，则拷贝事件到用户态，然后返回。如果为空，则加入epfd的等待队列睡眠，等待被唤醒（如果设置超时的话，则要么超时醒来，要么有事件就绪，醒来）。进程醒过来，对就绪链表逐一拷贝到用户态。这里是先拷贝中间链表，在拷贝期间发生的事件仍然能够加入到就绪链表，等待下次epoll_wait收集。 3.3 ET和LT的实现其实内核在实现ET和LT的时候非常简单。就是在拷贝就绪链表的时候，内核判断事件类型，如果是ET模式，则直接清除掉。如果是LT模式，只要相应的fd仍是就绪的，则重新加入就绪链表。 另外有一个细节：在注册感兴趣的事件的时候，内核就会检查fd是否就绪，如果就绪，则直接加入就绪链表（可见，就绪事件加入就绪链表不一定是设备驱动触发的）。 3.4 Epoll的优点 使用红黑树管理监听的文件描述符，高效的插入、删除操作。 事件只需注册一次。 支持监听的文件描述符的数量非常大。 每次返回的是就绪的fd数组。Select、Poll需要遍历整个所有描述符。 本文完。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中断和异常——内核的动力]]></title>
    <url>%2F2018%2F03%2F01%2F2018-3-1InterruptAndException%2F</url>
    <content type="text"><![CDATA[本文内容关注一种内核工作的基本机制——中断和异常。标题称这种机制为内核的动力，或许不那么恰当，主要想强调中断和异常对内核工作的重要性。对于操作系统上层的应用程序开发者而言，或许感觉离中断和异常的机制很远，因为我们不需要开发内核。但是毕竟我们使用的是内核所提供的各种服务，理解内核的基本运作原理能够帮助我们更好地写程序、优化程序。 问在前面： 通常所说的“陷入内核”，是怎么个陷入法呢？ 我们的网卡收到数据，内核怎么知道该去处理数据了呢？时刻去轮询一下，恐怕不太现实？ 我们访问了一个非法的内存地址，或者执行了一个除0操作。毫无悬念，内核崩溃。那么内核是怎么知道进程崩溃了，该来收拾这个烂摊子了？ 直观来看，内核是什么？内核地址空间和进程的地址空间相互独立？ 我们都知道，Linux内核与进程的地址空间相互独立。这是什么意思？直观的比喻就是，每个进程在自己的内存区域工作，内核也在自己的区域工作，它们之间互相都是不可见的。（这点由虚拟内存管理机制保证）。在同一个地址空间内部，我们可以简单的使用函数调用（或者说过程调用）来使用别的函数提供的功能。比如，你自己写的程序，函数funcA调用funcB。又比如，在Linux内核内部，函数可以直接调用。但是在两个地址空间之间，交互就没那么容易了。比如，如果进程想要使用内核提供的服务（文件读写，网络通信等等），怎么做呢？答案是，系统调用（陷入内核）。 系统调用怎么实现呢？ 系统调用的目的就是进程能够使用内核的服务。但是具体是怎么向内核发起调用（请求）的呢。答案是中断。我们知道，CPU不断的取指令，执行指令。我们跟CPU约定好，如果遇到一种指令，叫“软中断指令”，CPU就保存当前进程的上下文，改变CPU的模式，然后跳转到内核的中断向量表，获取“软中断处理程序”的地址，然后执行。这就算陷入内核了。 内核是由中断驱动的一个程序实体 内核由各种各样的服务组件组成，各种系统调用、文件系统、网络系统、调度子系统等等。各种各样的内核活动的产生并不是凭空的，都是需要某种方式驱动，这就是中断。调度：定时器按一个时间片的周期触发一个中断，内核由此触发一次调度过程。系统调用：进程触发一个软中断，内核由此执行一个具体的系统服务。设备驱动:网卡收到数据，触发一次中断，内核由此执行一次对网卡的读操作。等等。 中断和异常本质上，中断和异常属于同一个范畴。 我们知道，CPU的工作就是不断的取指令，执行指令。每执行一次指令，或者在执行指令期间会发生三种情况： 指令按预想的结果执行，然后取下一条指令，继续执行。 这是一条特殊指令，预示一种异常的流向。比如除0操作，越界访问，缺页异常或者系统调用的软中断指令。 执行期间，外部设备触发了一个中断，而CPU不得不响应这个中断，转去执行中断服务程序。这是另一种类型的异常流向。 对于第2种情况，我们称之为异常。就是CPU执行指令过程中出现的异常情况。因为它是CPU执行完一条指令之后触发的，所以也称为“同步中断”。对于第3种情况，称为“中断”，CPU随时都有可能收到外部设备的中断，具有随机性，也称之为“异步中断”。 不管是中断还是异常，它们的处理程序都是内核来执行的。 中断上下文与进程上下文首先谈进程上下文： 示例： 同样是一次read调用，进程A和进程B得到效果是不一样的，进程A读取文件a，获取到x个字节；进程B读取文件b，获取到y个字节。而内核肯定只有一个read调用。 内核如何做到区别对待？ 只告诉内核执行什么系统调用是不够的，内核必须知道，为哪个进程服务，读取哪个文件，预期读取多少个字节，要拷贝用户缓冲的目的地址等等。简言之，内核需要一个执行环境，这个环境就是所谓的“进程上下文”。即，当一个进程正在进行时，CPU所有寄存器中的值、进程的状态以及堆栈中的内容称之为进程的上下文。所以，进程执行系统调用，“内核代表进程执行，在进程上下文”。 再来就是中断上下文，和进程上下文是一个道理，当硬件触发中断的时候，内核需要获取到当前该硬件的各种变量和参数，内核根据这些参数来执行中断服务程序。而硬件传过来的各种参数和内核需要保存的一些环境（被中断的进程环境），可以看作是中断上下文。 总结总的来说，内核就是一堆处理过程合成的实体。它基本没有主动性，靠的是各种中断来驱动的。进程有需求了，触发中断告诉它；程序执行出错了，触发中断告诉它；设备状态变化了，还是触发中断告诉它；时间片到期，该调度了，触发中断告诉它。]]></content>
      <categories>
        <category>操作系统</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[重新训练自己的大脑]]></title>
    <url>%2F2018%2F01%2F12%2F%E5%AD%A6%E4%B9%A0%E4%B9%8B%E9%81%93%2F</url>
    <content type="text"><![CDATA[阅读《学习之道》，重新训练自己的大脑。 What 专注思维和发散思维 工作记忆和长期记忆 回想和提取练习 组块构建和避免能力错觉 专注思维和发散思维大脑存在两种思维模式交替运作：专注模式和发散模式。专注模式擅长在经验、旧有的神经连接中寻找解决方法；发散模式（无意识思考）则是在不经意间触发灵感。 沉于专注模式太久，会陷入思维困境无法自拔；没有专注一段时间便进入发散模式，往往陷入“认知错觉”（总感觉自己在学习，但实际上没有）。 学习新概念新知识块，首先需要快速浏览总体把握，并且尽可能描述清楚发现的问题。之后带着清晰的问题进入深度阅读，在深度阅读的过程中，不断明确问题，并尝试求解。在一段时间（1小时），问题仍旧不能解决，此时要转移注意力，有意识地切换成发散模式（散步，听音乐）。反复之。 专注模式下，问题必须清晰。 工作记忆和长期记忆两种记忆系统：工作记忆和长期记忆 工作记忆是瞬时记忆，要想让工作记忆转存到长期记忆，需要时间也需要能量。也就是说，需要有时间表适时地不断排演重复，对其施加能量，才能触发生成长期的神经连接。一开始，最好24小时内回顾一次。之后每天重复一次，再后来，每周甚至几周重复一次。 这就意味着，需要有跟踪学习项目的记录。 回想，提取练习回想（提取练习）是比一遍遍阅读材料更有效的，但是常常被忽略。 学习时，自我测验和做提取练习时最有效果的。 初次学到、还颇有挑战性的知识，最好是24小时内亲近一下。然后几天，一周，几周，几个月。 要想考出好成绩或在此基础上创造性思考，你就必须让它们牢牢地钉在记忆里。 组块构建和避免能力错觉要熟练的掌握知识，就要创造一些概念组块——通过赋予意义将分散的信息碎片组合起来的过程。 构成组块的基本步骤 注意力集中在原始信息本身的意义上 理解信息形成组块的接口，即它对外界的意义 获取背景信息，反复推敲组块和外界的连接，即其存在的意义和何时何地使用它们 搭建组块资料库的过程，也是训练大脑的过程。 仅仅看一遍问题答案，就以为自己会了，这就是能力错觉。从笔记里挑一个概念，看看自己能回忆起多少内容，同时试着理解所回忆的内容。此时，回想会发挥很大作用。 How Questions List ToDo List 组块构建跟踪——笔记或Blog 番茄时间(专注模式) Q List每开始一次新知识的学习，准备问题列表。在专注模式在，不断清晰、明确、深刻对问题本身和答案的理解。 组块构建跟踪笔记本专门一白页（简要）、组块构建是Blog或笔记的形式 根据组块构建的步骤，一开始不应是总结式的。 按大类别，将碎片化的知识小块，逐个理解（其本身，接口，与外界联系） 心中已开始有全貌的认识，便开始整理、组块 在尚未基本固定下来整个知识架构之前，按一定的时间周期，不断回想提取、理解。 ToDo List每天睡觉前，写下明天要做的重要的事项。 避免拖延。 心态 战胜恐惧，别怕落在别人后面 拖延——令你没有足够时间处于专注模式，走马观花 好好睡觉]]></content>
      <categories>
        <category>效率</category>
      </categories>
      <tags>
        <tag>自我提升</tag>
        <tag>学习方法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[static关键字]]></title>
    <url>%2F2017%2F12%2F05%2Fstatic%2F</url>
    <content type="text"><![CDATA[何时使用static 请况一:当我们定义一个函数,该函数仅限于在定义它的源文件下使用,此时可以使用”static”修饰,以对外界隐藏该函数. 情况二:同样,定义一个全局变量,该变量仅在定义它的源文件下使用,此时可以使用”static”修饰,达到隐藏的目的. 情况三:对于一个局部变量,如果我们有意不让其存储在栈(自动变量)上,而是存储在静态存储区(.data,.bss),可以使用static修饰.前两种情况都是限定符号的作用域,第三种情况属于改变变量的生命周期. static的作用如何实现的首先清楚c/c++的分离式编译,每个.c文件都首先经过编译成目标文件(.o文件),再经过链接形成可执行文件。 static修改链接属性 使用static修饰全局变量或者函数，其实修饰的都是符号。对编译其来说，以static修饰的符号，其属性的本地属性，即在链接的时候，不会被链接器处理。这样就达到了向外界（其他目标文件）隐藏的目的。 static局部变量（静态局部变量） 静态局部变量仅仅是编译器在编译的时候，在程序的静态存储区（.bss,.data）为该变量预留空间。未初始化的静态局部变量存储在.bss段，已初始化的静态局部变量存储在.data。其生命周期就从初始化时刻到程序结束。栈上变量（自动变量）的生命周期只局限函数内部。 static和externextern并不能改变static的作用效果。 extern关键字的作用仅仅是告诉编译器，该符号的定义在外部。 对于全局变量来说，extern的作用是告诉编译器，该符号在其他源文件里面。 对于函数来说，extern的作用和#include “*.h”的作用是相似的，相当于声明。在两个目标模块的联系仅仅是几个函数，就可以使用这种方法，而不需要include包含整个头文件。]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基本UDP编程]]></title>
    <url>%2F2017%2F12%2F01%2FUDP_socket%2F</url>
    <content type="text"><![CDATA[UDP 用户数据报协议TCP的通信流程好比“打电话”，拨通号码，需要等对方接起电话（建立了通话渠道），才能进行交流。UDP的通信流程就好比“写信件”，写好信，填好对方的地址和名字，就可以寄出去了。如果没有告知对方，对方并不会知道他将会收到你的一封信。可能因为某些原因（信在运输被弄掉了等等），对方收不到你的信，你也不知道对方收到了没有。更糟糕的是，信可能到对方家里了，但是他不在，或者没有从邮箱里拿出你的信。类似信件的通信行为，UDP把用户进程每次传过来的数据不加拆解、完整的打包成udp数据包交给IP协议层。 UDP协议面向非连接。“非连接”怎么理解？就是说，UDP不管通信对方是否准备好接收消息，甚至不管对方是不是存在。直接把数据打包交给IP层去发送就是了。不像TCP，需要建立起一个连接，才能发送数据。 UDP协议是不可靠的。适用于一次传输数据量较少的通信。 UDP头部UDP基本通信模型请求——应答模式 recvfrom和sendto函数这两个函数是UDP下的读写函数，类似于标准的read和write函数。可以说，这两个函数就是为UDP而生的。为什么这样说呢？ 因为UDP是不建立连接的数据传输，这里隐含：对于一个udp套接字，它可以一会儿发给a服务器，一会发给b服务器。同样，它可以接受来自不同IP主机的数据包。（只要知道其地址和端口号就行了）。也就是说，每次发送/接收的行为都是独立的，那么怎么区分数据包呢？解决方法就是在read/write函数加两个参数：地址结构体及其长度。这也就演变出两个函数：recvfrom和sendto. TCP是面向连接的，单向的。recvfrom/sendto没有必要使用在TCP上。123#include &lt;sys/socket.h&gt;ssize_t recvfrom(int sockfd, void* buff, size_t hbytes, int flags, struct sockaddr* from, socklen_t *addrlen);ssize_t sendto(int sockfd, const void* buff, size_t nbytes, int flags, struct sockaddr* to, socklen_t addrlen); 针对这两个函数，注意几点： recvfrom的地址结构及其长度参数都是指针类型，即“值——结果”参数。sendto的地址结构长度是“值”类型。 recvfrom返回值为0是允许的，且不像TCP，返回0就代表对端关闭连接。对于UDP来说，写一个长度为0的数据报是允许的。 recvfrom的地址结构指针是NULL，那么其长度也必须为NULL，表示我们不关心数据发送者的协议地址。 各种小问题数据报丢了。。。客户端sendto一个数据报之后，就兴高采烈转入recvfrom中阻塞等待接收。凡是都有万一，万一数据报在路上被路由器丢弃了，或者服务器根本不存在，又或者服务器返回应答了但是应答丢了。。。会出现什么情况：客户端永久阻塞在recvfrom调用。 一般的解决方法是：给recvfrom调用设置一个超时。 数据报不请自来——验证响应客户端或服务器本来在等待A端的数据包，但是却接收到了非A的数据报。如果应用进程不想与之通信，就需要有机制来忽略或处理这样的情况。 解决方法：通过recvfrom传回来的地址结构来判断是否是我们想要的响应。 服务器进程未运行客户端在未获知服务器是否启动的情况下，就像服务器发送数据包，会发生这样的情况，即服务器进程还没有启动时，客户端就sendto一个数据包，然后直接转入到recvfrom中，那么什么也不会发生。客户端将永远阻塞在recvfrom。为什么是这样的？ 针对IP协议来说，如果目标进程不可达，服务器端将会返回一个“端口不可达”ICMP错误（异步错误）。但是在默认情况（未连接）下，这个错误是不会被发送进程感知到的（原因后解）。 sendto成功返回仅仅表示在接口输出队列中具有足够的空间存放本次发送形成的IP数据报。也就不能说明对方已经收到数据报。 一个基本规则就是：对于一个UDP套接字，由他引发的异步错误并不返回给套接字本身，除非该UDP套接字已经连接。为什么这样做呢？原因其实很简单，想象一个场景，一个未连接UDP套接字同时发给多个不同的主机，其中有个主机响应了ICMP错误，如果将此异步错误传递给UDP套接字，那么它也判断不了是哪个通信方出现问题。已连接的UDP套接字可以感知到ICMP错误，就是因为它仅仅只有一个对端。 一言：UDP套接字进程感知不了ICMP错误，除非它是已连接的。 UDP的connect行为与TCP的connect操作有三次握手过程不同，UDP的connect仅仅是检查是否存在立即可知的错误（地址是不是错误的），把套接字的目标地址和目标端口提前填好而已。 设置好目的IP和目的端口的UDP套接字称为“已连接UDP套接字”。它与未连接UDP套接字有三处不同： 设置好目的IP和目的端口号，也就不用每次调用sendto和recvfrom这样需要填地址结构的函数了，可以像TCP一样，调用write/send。 同样的，recvfrom也不必使用，而改用read、recv或recvmsg。 由已连接UDP套接字引发的异步错误将返回它们所在的进程，而未连接UDP套接字不接受任何异步错误。 已连接UDP套接字只是确定在当下要通信的对端，是可变的。改变目的IP和目的端口的方法就是再次调用connect。 已连接和未连接UDP套接字的性能 在一个未连接的UDP套接字上调用两次sendto函数，内核行为经历6个步骤： 连接套接字； 输出第一个数据报； 断开套接字连接； 连接套接字； 输出第二个数据报； 断开套接字连接； 在一个已连接的UDP套接字上调用两次sendto函数，内核行为经历6个步骤： 连接套接字； 输出第一个数据报； 输出第二个数据报； 断开套接字连接；]]></content>
      <categories>
        <category>技术笔记</category>
      </categories>
      <tags>
        <tag>网络编程</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TIME_WAIT状态]]></title>
    <url>%2F2017%2F11%2F03%2F2018-5-19TCP_TIME_WAIT%2F</url>
    <content type="text"><![CDATA[本文关注内容：TCP连接的TIME_WAIT状态。TCP很重要的一个特性就是可靠性，这是在TCP协议的设计中考虑的重点。TIME_WAIT状态的引入，也是在为TCP可靠性做贡献。 为认识TIME_WAIT状态最基本的设计初衷，我们引一个场景： 在四次挥手阶段，主动关闭方接受被动关闭方的FIN包，然后发送给被动关闭方ACK。此时如果协议策略是直接关闭 连接，清理连接占用的资源。这样会出现问题：如果最后的ACK包丢失了，被动关闭方等待接受ACK超时，就要求重 传。此时主动关闭方已经没有了那个连接的信息，所以发送一个RST。被动关闭方收到RST，一脸茫然。。。 所以，主动关闭方在发给对端ACK包时，不能直接关闭连接，需要保证对端能够收到ACK包，必要时能够重传ACK包。此时主动关闭方所处的状态就是所谓的“TIME_WAIT”状态。 什么是TIME_WAIT状态TIME_WAIT 发生对象：TCP连接的主动关闭方（如果双方同时关闭，则都会进入TIME_WAIT状态） 发生时机：四次挥手阶段，主动关闭方发出对被动关闭方FIN报文的ACK报文后。 持续时长：2 * MSL （MSL：报文的最大生存时间，伯克利实现设置为30s） TIME_WAIT的作用（用以解决什么问题）文章开头我们提到一个TIME_WAIT的好处：（1）主动关闭方进入TIME_WAIT状态确保被动关闭方能够接收到FIN的ACK。除此之外，能够保证：（2）旧连接断开，一个一摸一样的新链接建立（源端口，源IP，目的端口，目的IP都一样），旧连接的数据包不会影响到新的连接。因为TIME_WAIT持续的时间，能够保证数据包在网络中消逝，而连接处于TIME_WAIT状态期间，主机不能使用当前的IP和端口组合建立连接。 TIME_WAIT有何负面影响TIME_WAIT状态需要持续2*MSL，长达1分钟，甚至更长。在这期间，该连接的端口不能用于建立新的连接。如果短时间内，关闭大量的连接，就会造成大量的TIME_WAIT。两方面的影响： 大量处于TIME_WAIT的连接，消耗主机内存资源（内核表示tcp的tuple）。 TCP协议用于表示端口的字段为16bit，也就是说，理论上最多可使用65535个端口号，实际上可使用的更少。如果短时间内大量的TIME_WAIT，端口耗尽，就无法再发起新的连接了。 如何避免TIME_WAIT状态解决： TCP选项：TCP_REUSEADDR （强制可以重新使用！） 参数：net.ipv4.tcp_tw_reuse和net.ipv4.tcp_tw_recycle（直接就不在TIME_WAIT状态呆着。。。） 连接池（不着急关闭） TCP_REUSEADDR ： 处于TIME_WAIT状态的socket是占有连接的，即不允许另一个socket绑定相同的ip和端口。TCP_REUSEADDR的作用就是：”允许处理TIME_WAIT的连接所占有的IP+端口组合得到复用”。不管之前的socket是否设置了该选项，只要当前的socket设置即可生效。 net.ipv4.tcp_tw_reuse = 1允许在系统重用处于TIME_WAIT连接的端口，作用类似与TCP_REUSEADDR；net.ipv4.tcp_tw_recycle = 1是启用TIME_WAIT快速回收，意味直接就不进入TIME_WAIT状态，靠时间戳区分是旧连接还是新连接的数据包。该功能在NAT环境下可能会出现严重问题。 连接池： 顾名思义，我们使用池子收集空闲的连接，而不是关闭它。这样就能减少TIME_WAIT状态的产生。这种解决方法适合特定的场景，比如数据库连接池。 本文完。]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
</search>
